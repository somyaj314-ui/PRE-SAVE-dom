# ğŸ¤– CODEBASE ARCHITECTURE & ML PRE-DETECTION FLOW

## ğŸ“‹ TABLE OF CONTENTS
1. [High-Level Architecture](#high-level-architecture)
2. [Complete Data Flow](#complete-data-flow)
3. [How ML Pre-Detection Works](#how-ml-pre-detection-works)
4. [Module Descriptions](#module-descriptions)
5. [Model Architecture](#model-architecture)
6. [Code Architecture Diagram](#code-architecture-diagram)

---

## ğŸ—ï¸ HIGH-LEVEL ARCHITECTURE

This is a **Chrome Extension** that captures configuration changes from web portals (FortiGate, Palo Alto) and uses Machine Learning to **predict the operation type** (CREATE, MODIFY, DELETE, etc.) before manual submission.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHROME EXTENSION ARCHITECTURE                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸŒ WEB PORTAL (Fortinet, Palo Alto, etc.)                     â”‚
â”‚  â”œâ”€ User fills form (policy, interface, route, etc.)           â”‚
â”‚  â””â”€ Clicks "Save" or "Create"                                 â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  CONTENT SCRIPT (content.js)                       â”‚        â”‚
â”‚  â”‚  â”œâ”€ Runs in webpage context                        â”‚        â”‚
â”‚  â”‚  â””â”€ Injects additional scripts                     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚               â”‚ window.postMessage()                           â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚       â”‚                  â”‚                 â”‚              â”‚   â”‚
â”‚       â–¼                  â–¼                 â–¼              â–¼   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Universal  â”‚  â”‚ ML Unified     â”‚  â”‚ ML       â”‚  â”‚URL â”‚   â”‚
â”‚  â”‚ Field      â”‚  â”‚ Collector      â”‚  â”‚ Inferenceâ”‚  â”‚Router    â”‚
â”‚  â”‚ Extractor  â”‚  â”‚                â”‚  â”‚          â”‚  â”‚    â”‚   â”‚
â”‚  â”‚ (Raw data) â”‚  â”‚ (Normalization)â”‚  â”‚(Predict) â”‚  â”‚    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚                  â”‚                 â”‚                  â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                          â–¼                                     â”‚
â”‚              Training Data Collection                         â”‚
â”‚              (JSON in memory + IndexedDB)                     â”‚
â”‚                          â”‚                                     â”‚
â”‚                          â–¼                                     â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â”‚  ğŸ”„ EXPORT (Ctrl+Shift+D)       â”‚                  â”‚
â”‚         â”‚  â”œâ”€ data.json (raw samples)     â”‚                  â”‚
â”‚         â”‚  â””â”€ model_data.json (trained)   â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                        â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         PYTHON BACKEND (Training)                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                  â”‚
    â”‚  preprocessing.py                              â”‚
    â”‚  â”œâ”€ Tokenization (TF-IDF)                       â”‚
    â”‚  â”œâ”€ Struct vector (field presence)              â”‚
    â”‚  â”œâ”€ Diff vector (changes hashed)                â”‚
    â”‚  â””â”€ Output: train.pkl (PyTorch tensors)         â”‚
    â”‚                                                  â”‚
    â”‚  train.py                                       â”‚
    â”‚  â”œâ”€ Load train.pkl                              â”‚
    â”‚  â”œâ”€ Build 3-expert MLP model                    â”‚
    â”‚  â”œâ”€ Train for 25 epochs                         â”‚
    â”‚  â””â”€ Output: model_artifacts.pkl                 â”‚
    â”‚                                                  â”‚
    â”‚  export_model.py                                â”‚
    â”‚  â”œâ”€ Extract weights, vocab, IDF                 â”‚
    â”‚  â””â”€ Output: model_data.json (JS-compatible)     â”‚
    â”‚                                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  model_data.json â†’ Back to Extension            â”‚
    â”‚  â””â”€ ML Inference runs in JS on next page load   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ COMPLETE DATA FLOW

### PHASE 1: DATA COLLECTION (Runtime)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 1: DATA COLLECTION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  STEP 1: PAGE LOAD                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  User navigates to: /firewall/policy/create or /firewall/policy/1
â”‚                                                                 â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚           â”‚ HTML Loads                      â”‚                  â”‚
â”‚           â”‚ (form, inputs, selects detected)â”‚                  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                        â”‚                                        â”‚
â”‚              â–¼         â–¼         â–¼                              â”‚
â”‚  universal_field_extractor.js FIRES                            â”‚
â”‚  â”œâ”€ MutationObserver detects form element                      â”‚
â”‚  â”œâ”€ Waits 500ms for Angular/React to populate                 â”‚
â”‚  â””â”€ Extracts BEFORE state (page load)                         â”‚
â”‚                                                                 â”‚
â”‚  Example BEFORE state:                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  {                                                              â”‚
â”‚    "name": null,                   â† Empty field               â”‚
â”‚    "srcintf": "port1",             â† Pre-filled               â”‚
â”‚    "dstintf": "port2",             â† Pre-filled               â”‚
â”‚    "action": null,                 â† Empty                     â”‚
â”‚    "enabled": true                 â† Has default              â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  Broadcasts: UNIVERSAL_MONITOR_START                           â”‚
â”‚               â†“                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 2: USER INTERACTS                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  User fills form:                                               â”‚
â”‚    - Sets name = "Allow HTTP"                                  â”‚
â”‚    - Selects action = "accept"                                 â”‚
â”‚    - Leaves dstintf as is                                      â”‚
â”‚                                                                 â”‚
â”‚  Detector tracks changes in real-time                          â”‚
â”‚  (listens to input events, change events, etc.)                â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 3: SAVE CLICKED                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  User clicks "Save" or "Create"                                â”‚
â”‚                                                                 â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚           â”‚ extractFormValues() fires     â”‚                     â”‚
â”‚           â”‚ (on click or API intercept)   â”‚                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                    â”‚                                             â”‚
â”‚         â–¼          â–¼          â–¼                                 â”‚
â”‚  universal_field_extractor.js captures AFTER state             â”‚
â”‚                                                                 â”‚
â”‚  Example AFTER state:                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  {                                                              â”‚
â”‚    "name": "Allow HTTP",           â† Changed                   â”‚
â”‚    "srcintf": "port1",             â† Same as before            â”‚
â”‚    "dstintf": "port2",             â† Same as before            â”‚
â”‚    "action": "accept",             â† Changed                   â”‚
â”‚    "enabled": true                 â† Same                      â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 4: CANONICAL MAPPING                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  Broadcasts: UNIVERSAL_EVENT_SAVED                             â”‚
â”‚               â†“                                                  â”‚
â”‚  ml-unified-collector.js receives event                        â”‚
â”‚                                                                 â”‚
â”‚  Step 4A: Detect Vendor & Object Type                          â”‚
â”‚  â”œâ”€ URL parsing: /firewall/policy/ â†’ vendor="fortigate"       â”‚
â”‚  â”œâ”€ Load vendor_field_map.json                                â”‚
â”‚  â””â”€ Identify: object_type="policy"                            â”‚
â”‚                                                                 â”‚
â”‚  Step 4B: Map to Canonical Fields                              â”‚
â”‚  â”œâ”€ Original field: "ng:$ctrl.policy.srcintf"                 â”‚
â”‚  â”œâ”€ Lookup in mapping: srcintf â†’ "source_interface"          â”‚
â”‚  â””â”€ Canonical field: "source_interface"                       â”‚
â”‚                                                                 â”‚
â”‚  Step 4C: Calculate Differences                                â”‚
â”‚  â”œâ”€ Before: {name: null, action: null}                        â”‚
â”‚  â”œâ”€ After: {name: "Allow HTTP", action: "accept"}            â”‚
â”‚  â””â”€ Changes: ["name", "action"]                               â”‚
â”‚                                                                 â”‚
â”‚  Step 4D: Infer Operation Type                                 â”‚
â”‚  â”œâ”€ Check identity field (e.g., "name")                       â”‚
â”‚  â”œâ”€ Before.name = null, After.name = "Allow HTTP"            â”‚
â”‚  â””â”€ Operation = "CREATE"                                       â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 5: CREATE SAMPLE & STORE                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Canonical Sample (normalized):                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  {                                                              â”‚
â”‚    metadata: {                                                  â”‚
â”‚      vendor: "fortigate",                                      â”‚
â”‚      object_type: "policy",                                    â”‚
â”‚      operation: "CREATE",                                      â”‚
â”‚      timestamp: 1766051559664                                  â”‚
â”‚    },                                                           â”‚
â”‚    data: {                                                      â”‚
â”‚      before: {                                                  â”‚
â”‚        name: null,                                              â”‚
â”‚        source_interface: "port1",                              â”‚
â”‚        dest_interface: "port2",                               â”‚
â”‚        action: null,                                            â”‚
â”‚        enabled: true                                           â”‚
â”‚      },                                                         â”‚
â”‚      after: {                                                   â”‚
â”‚        name: "Allow HTTP",                                     â”‚
â”‚        source_interface: "port1",                              â”‚
â”‚        dest_interface: "port2",                               â”‚
â”‚        action: "accept",                                       â”‚
â”‚        enabled: true                                           â”‚
â”‚      }                                                          â”‚
â”‚    },                                                           â”‚
â”‚    changes: [                                                   â”‚
â”‚      { field: "name", before: null, after: "Allow HTTP" },    â”‚
â”‚      { field: "action", before: null, after: "accept" }       â”‚
â”‚    ]                                                            â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  Store in:                                                      â”‚
â”‚  â”œâ”€ Memory: allSamples[]                                       â”‚
â”‚  â”œâ”€ IndexedDB: persistent storage                              â”‚
â”‚  â””â”€ Model: for ML training                                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PHASE 2: ML PRE-DETECTION (Runtime)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PHASE 2: ML PRE-DETECTION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  STEP 1: MODEL LOADED                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚  On page load:                                                  â”‚
â”‚  â”œâ”€ model_data.json fetched (contains trained weights)         â”‚
â”‚  â”œâ”€ MLInference class instantiated                             â”‚
â”‚  â””â”€ console: "ğŸ§  ML Inference Engine Loaded"                   â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 2: CAPTURE CURRENT FORM STATE                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  When user fills form, ml-unified-collector captures:          â”‚
â”‚  â”œâ”€ data.after = {name: "Allow HTTP", action: "accept", ...}  â”‚
â”‚  â”œâ”€ changes = ["name", "action"]                               â”‚
â”‚  â””â”€ metadata.object_type = "policy"                            â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 3: FEATURE EXTRACTION (2 passes)                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚                                                                 â”‚
â”‚  Pass A: TEXT FEATURES (TF-IDF Vectorization)                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚                                                                 â”‚
â”‚  Input: Field names + values                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ name: "Allow HTTP"                  â”‚                      â”‚
â”‚  â”‚ action: "accept"                    â”‚                      â”‚
â”‚  â”‚ source_interface: "port1"           â”‚                      â”‚
â”‚  â”‚ dest_interface: "port2"             â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                 â”‚
â”‚  Process:                                                       â”‚
â”‚  1. Combine into text:                                          â”‚
â”‚     "name Allow HTTP action accept source_interface port1 ..."â”‚
â”‚                                                                 â”‚
â”‚  2. Tokenize (lowercase, word boundary):                        â”‚
â”‚     ["name", "allow", "http", "action", "accept", ...]        â”‚
â”‚                                                                 â”‚
â”‚  3. Look up in vocabulary (model.tfidf.vocab):                â”‚
â”‚     {                                                           â”‚
â”‚       "allow": 0,                                               â”‚
â”‚       "accept": 15,                                             â”‚
â”‚       "http": 234,                                              â”‚
â”‚       ...                                                       â”‚
â”‚     }                                                           â”‚
â”‚                                                                 â”‚
â”‚  4. Calculate TF (Term Frequency):                              â”‚
â”‚     - Count occurrences of each token                          â”‚
â”‚     - For our text: "allow" appears 1x, "accept" 1x, etc.     â”‚
â”‚                                                                 â”‚
â”‚  5. Apply IDF (Inverse Document Frequency):                    â”‚
â”‚     - Tokens like "the", "policy" get low weights              â”‚
â”‚     - Rare tokens get high weights                             â”‚
â”‚     - tf_final = tf * idf                                      â”‚
â”‚                                                                 â”‚
â”‚  6. L2 Normalize:                                               â”‚
â”‚     - Ensure vector magnitude = 1                               â”‚
â”‚     - Makes comparison scale-invariant                         â”‚
â”‚                                                                 â”‚
â”‚  Output: textVec [2000 dimensions]                             â”‚
â”‚  Example (truncated): [0.12, 0.0, 0.45, ..., 0.02, 0.0, ...]  â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  Pass B: STRUCT FEATURES (Field Presence Binary)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚                                                                 â”‚
â”‚  Input: data.after values                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ name: "Allow HTTP"       â† has value                        â”‚
â”‚  â”‚ action: "accept"         â† has value                        â”‚
â”‚  â”‚ comments: null           â† NO value                         â”‚
â”‚  â”‚ schedule: undefined      â† NO value                         â”‚
â”‚  â”‚ enabled: true            â† has value                        â”‚
â”‚  â”‚ port_lower: []           â† EMPTY array â†’ NO value           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                 â”‚
â”‚  Process:                                                       â”‚
â”‚  For each canonical field (sorted order):                      â”‚
â”‚  â”œâ”€ 1 if field has value (not null/false/empty)               â”‚
â”‚  â””â”€ 0 if field is null/false/empty                            â”‚
â”‚                                                                 â”‚
â”‚  Output: structVec [847 dimensions]                            â”‚
â”‚  Example: [1, 1, 0, 1, 0, 1, 1, 0, ..., 1]                    â”‚
â”‚           â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚    â”‚                                â”‚
â”‚           â””â”€ For each of 847 canonical fields                  â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  Pass C: DIFF FEATURES (Changes Hashed)                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚                                                                 â”‚
â”‚  Input: changes = [                                             â”‚
â”‚    { field: "name", ... },                                     â”‚
â”‚    { field: "action", ... }                                    â”‚
â”‚  ]                                                              â”‚
â”‚                                                                 â”‚
â”‚  Process:                                                       â”‚
â”‚  1. Extract field names: ["name", "action"]                    â”‚
â”‚                                                                 â”‚
â”‚  2. Hash each field name to [0, 199]:                          â”‚
â”‚     â”œâ”€ hash("name") = 12345 â†’ idx = 12345 % 200 = 45          â”‚
â”‚     â”œâ”€ hash("action") = 98765 â†’ idx = 98765 % 200 = 165       â”‚
â”‚     â””â”€ Similar to JS String.prototype implementation          â”‚
â”‚                                                                 â”‚
â”‚  3. Create 200-dim binary vector:                              â”‚
â”‚     diffVec[45] = 1        â† "name" changed                    â”‚
â”‚     diffVec[165] = 1       â† "action" changed                  â”‚
â”‚     All others = 0                                              â”‚
â”‚                                                                 â”‚
â”‚  Output: diffVec [200 dimensions]                              â”‚
â”‚  Example: [0, 0, ..., 1, ..., 0, ..., 1, ..., 0]              â”‚
â”‚                         45       165                            â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 4: FORWARD PASS (Neural Network Inference)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚                                                                 â”‚
â”‚  Architecture:                                                  â”‚
â”‚                                                                 â”‚
â”‚  TEXT EXPERT (Text MLP)                                        â”‚
â”‚  â”œâ”€ Input: textVec [2000]                                     â”‚
â”‚  â”œâ”€ Layer 1: [2000] â†’ [128] with ReLU                         â”‚
â”‚  â”œâ”€ Layer 2: [128] â†’ [128]                                    â”‚
â”‚  â””â”€ Output: txtOut [128]                                      â”‚
â”‚                                                                 â”‚
â”‚  STRUCT EXPERT (Struct MLP)                                    â”‚
â”‚  â”œâ”€ Input: structVec [847]                                    â”‚
â”‚  â”œâ”€ Layer 1: [847] â†’ [128] with ReLU                          â”‚
â”‚  â”œâ”€ Layer 2: [128] â†’ [128]                                    â”‚
â”‚  â””â”€ Output: structOut [128]                                   â”‚
â”‚                                                                 â”‚
â”‚  DIFF EXPERT (Diff MLP)                                        â”‚
â”‚  â”œâ”€ Input: diffVec [200]                                      â”‚
â”‚  â”œâ”€ Layer 1: [200] â†’ [128] with ReLU                          â”‚
â”‚  â”œâ”€ Layer 2: [128] â†’ [128]                                    â”‚
â”‚  â””â”€ Output: diffOut [128]                                     â”‚
â”‚                                                                 â”‚
â”‚  FUSION LAYER                                                   â”‚
â”‚  â”œâ”€ Concatenate: [128] + [128] + [128] = [384]               â”‚
â”‚  â”œâ”€ Final linear: [384] â†’ [num_classes]                       â”‚
â”‚  â””â”€ Output: logits = raw predictions for each class           â”‚
â”‚                                                                 â”‚
â”‚  SOFTMAX â†’ Probabilities                                        â”‚
â”‚  â””â”€ Convert logits to probabilities [0, 1]                    â”‚
â”‚     (sum to 1)                                                 â”‚
â”‚                                                                 â”‚
â”‚  Example Output Probabilities:                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  {                                                              â”‚
â”‚    "POLICY_CREATED": 0.85,      â† PREDICTED (highest)         â”‚
â”‚    "POLICY_MODIFIED": 0.10,                                    â”‚
â”‚    "POLICY_DELETED": 0.03,                                     â”‚
â”‚    "INTERFACE_CREATED": 0.02                                   â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 5: RETURN PREDICTION                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  {                                                              â”‚
â”‚    label: "POLICY_CREATED",    â† Most likely operation        â”‚
â”‚    confidence: 0.85,            â† How confident (0.85 = 85%)   â”‚
â”‚    probabilities: [0.85, ...],  â† All class probabilities      â”‚
â”‚    debug: {                                                     â”‚
â”‚      dims: {                                                    â”‚
â”‚        text: 2000,                                             â”‚
â”‚        struct: 847,                                            â”‚
â”‚        diff: 200                                               â”‚
â”‚      }                                                          â”‚
â”‚    }                                                            â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  This is logged to console & UI immediately!                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PHASE 3: MODEL TRAINING (Python Backend)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 3: MODEL TRAINING (Python)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  STEP 1: DATA EXPORT                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚  User exports collected data: Ctrl+Shift+D                     â”‚
â”‚  â”œâ”€ data.json: ~1000 samples (raw canonical format)            â”‚
â”‚  â””â”€ model_data.json: previous trained model (if exists)        â”‚
â”‚                                                                 â”‚
â”‚  data.json structure:                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  {                                                              â”‚
â”‚    "samples": [                                                 â”‚
â”‚      {                                                          â”‚
â”‚        "metadata": {                                            â”‚
â”‚          "vendor": "fortigate",                                 â”‚
â”‚          "object_type": "policy",                              â”‚
â”‚          "operation": "CREATE",                                â”‚
â”‚          "timestamp": 1766051559664                            â”‚
â”‚        },                                                       â”‚
â”‚        "data": {                                                â”‚
â”‚          "before": {...},                                      â”‚
â”‚          "after": {...}                                        â”‚
â”‚        },                                                       â”‚
â”‚        "changes": [...]                                        â”‚
â”‚      },                                                         â”‚
â”‚      ... (1000 total)                                           â”‚
â”‚    ]                                                            â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 2: PREPROCESSING (preprocessing.py)                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚                                                                 â”‚
â”‚  Input: data.json (1000 samples)                               â”‚
â”‚                                                                 â”‚
â”‚  Process:                                                       â”‚
â”‚  â”œâ”€ Load sklearn TfidfVectorizer (not fitted yet)              â”‚
â”‚  â””â”€ For each sample, extract 4 features:                       â”‚
â”‚                                                                 â”‚
â”‚  Feature 1: TEXT (TFIDF)                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  1. Combine field names + values from data.after               â”‚
â”‚     "name Allow HTTP action accept source_interface port1 ..." â”‚
â”‚                                                                 â”‚
â”‚  2. Fit TfidfVectorizer on all texts                           â”‚
â”‚     â”œâ”€ Learn vocabulary (2000 most common tokens)              â”‚
â”‚     â”œâ”€ Calculate IDF weights                                   â”‚
â”‚     â””â”€ Create vocab map & idf array                            â”‚
â”‚                                                                 â”‚
â”‚  3. Transform each text to 2000-dim TF-IDF vector              â”‚
â”‚     Output: tfidf_vectors [1000 Ã— 2000]                        â”‚
â”‚                                                                 â”‚
â”‚  Feature 2: STRUCT (Binary Field Presence)                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  1. Collect all canonical fields from all samples              â”‚
â”‚     all_keys = {"name", "action", "srcintf", ...}              â”‚
â”‚     sorted_keys = sorted list (for consistency)                â”‚
â”‚                                                                 â”‚
â”‚  2. For each sample, create binary vector                      â”‚
â”‚     â”œâ”€ For each field in sorted_keys:                          â”‚
â”‚     â”‚  â”œâ”€ 1 if field exists and has value                     â”‚
â”‚     â”‚  â””â”€ 0 if field is null/false/empty                      â”‚
â”‚     â””â”€ Result: [1, 0, 1, 1, 0, ...] (847 dims)               â”‚
â”‚                                                                 â”‚
â”‚  3. Stack all vectors                                          â”‚
â”‚     Output: structs [1000 Ã— 847]                               â”‚
â”‚                                                                 â”‚
â”‚  Feature 3: DIFF (Hashed Field Changes)                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚  1. For each sample, get list of changed fields                â”‚
â”‚     changes = ["name", "action"]                               â”‚
â”‚                                                                 â”‚
â”‚  2. Hash each field name (mirror JS hash in Python)            â”‚
â”‚     â”œâ”€ Implement same hash function as ml-inference.js         â”‚
â”‚     â”œâ”€ Hash("name") % 200 = 45                                 â”‚
â”‚     â””â”€ Hash("action") % 200 = 165                              â”‚
â”‚                                                                 â”‚
â”‚  3. Create 200-dim binary vector                               â”‚
â”‚     diffVec[45] = 1, diffVec[165] = 1, rest = 0               â”‚
â”‚                                                                 â”‚
â”‚  4. Stack all vectors                                          â”‚
â”‚     Output: diffs [1000 Ã— 200]                                 â”‚
â”‚                                                                 â”‚
â”‚  Feature 4: LABELS (Ground Truth)                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  Extract label from metadata.operation                         â”‚
â”‚  Example: "POLICY_CREATED"                                     â”‚
â”‚                                                                 â”‚
â”‚  Create label mapping:                                         â”‚
â”‚  {                                                              â”‚
â”‚    "POLICY_CREATED": 0,                                        â”‚
â”‚    "POLICY_MODIFIED": 1,                                       â”‚
â”‚    "POLICY_DELETED": 2,                                        â”‚
â”‚    "INTERFACE_CREATED": 3,                                     â”‚
â”‚    ...                                                         â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  Output: labels [1000] with class indices                      â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  Output: train.pkl (pickled dict)                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚  {                                                              â”‚
â”‚    "texts": ["text1", "text2", ...],              [1000]       â”‚
â”‚    "tfidf_vectors": [[0.12, ...], [...]],        [1000Ã—2000]   â”‚
â”‚    "structs": [[1, 0, 1, ...], [...]],           [1000Ã—847]    â”‚
â”‚    "diffs": [[0, ..., 1, ...], [...]],           [1000Ã—200]    â”‚
â”‚    "labels": ["POLICY_CREATED", ...],             [1000]       â”‚
â”‚    "label_to_idx": {...},                         (mapping)    â”‚
â”‚    "vectorizer": TfidfVectorizer(...),            (sklearn obj)â”‚
â”‚    "struct_dim": 847,                             (feature dim)â”‚
â”‚    "diff_dim": 200                                (feature dim)â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 3: MODEL TRAINING (train.py)                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚                                                                 â”‚
â”‚  Input: train.pkl                                              â”‚
â”‚                                                                 â”‚
â”‚  1. Load preprocessed data                                     â”‚
â”‚     â”œâ”€ Extract tensors: texts, tfidf_vectors, structs, etc.   â”‚
â”‚     â””â”€ Create PyTorch DataLoader (batch_size=4)               â”‚
â”‚                                                                 â”‚
â”‚  2. Initialize 3-Expert Model                                  â”‚
â”‚                                                                 â”‚
â”‚     class MultiheadModel:                                      â”‚
â”‚     â”œâ”€ TEXT EXPERT (MLP):                                      â”‚
â”‚     â”‚  â””â”€ 2000 â†’ 128 (ReLU) â†’ 128                            â”‚
â”‚     â”œâ”€ STRUCT EXPERT (MLP):                                    â”‚
â”‚     â”‚  â””â”€ 847 â†’ 128 (ReLU) â†’ 128                             â”‚
â”‚     â”œâ”€ DIFF EXPERT (MLP):                                      â”‚
â”‚     â”‚  â””â”€ 200 â†’ 128 (ReLU) â†’ 128                             â”‚
â”‚     â””â”€ CLASSIFIER:                                             â”‚
â”‚        â””â”€ 384 (concat) â†’ num_classes                          â”‚
â”‚                                                                 â”‚
â”‚     Total Parameters: ~200K                                    â”‚
â”‚                                                                 â”‚
â”‚  3. Training Loop (25 epochs)                                  â”‚
â”‚                                                                 â”‚
â”‚     For epoch 1 to 25:                                         â”‚
â”‚       For batch in DataLoader:
â”‚         1. Forward pass: y_pred = model(text, struct, diff)   â”‚
â”‚         2. Calculate loss: loss = CrossEntropyLoss(y_true)    â”‚
â”‚         3. Backward pass: loss.backward()                      â”‚
â”‚         4. Update weights: optimizer.step() (Adam, lr=1e-3)   â”‚
â”‚         5. Log loss                                             â”‚
â”‚                                                                 â”‚
â”‚     Example Training Progress:                                 â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚     Epoch  1/25 | Loss: 2.1234 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (50%)     â”‚
â”‚     Epoch  2/25 | Loss: 1.8900 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (63%)     â”‚
â”‚     Epoch  3/25 | Loss: 1.6234 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (72%)     â”‚
â”‚     ...                                                         â”‚
â”‚     Epoch 25/25 | Loss: 0.3245 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ (95%)     â”‚
â”‚                                                                 â”‚
â”‚  4. Save Model Artifacts                                       â”‚
â”‚     â”œâ”€ model.state_dict() (all weights & biases)               â”‚
â”‚     â”œâ”€ vectorizer (sklearn TfidfVectorizer)                    â”‚
â”‚     â”œâ”€ label_to_idx mapping                                    â”‚
â”‚     â”œâ”€ struct_dim (847)                                        â”‚
â”‚     â””â”€ diff_dim (200)                                          â”‚
â”‚                                                                 â”‚
â”‚     Output: model_artifacts.pkl                                â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                 â”‚
â”‚  STEP 4: EXPORT TO JAVASCRIPT (export_model.py)               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚                                                                 â”‚
â”‚  Input: model_artifacts.pkl                                    â”‚
â”‚                                                                 â”‚
â”‚  Process:                                                       â”‚
â”‚  1. Extract TF-IDF data                                        â”‚
â”‚     â”œâ”€ vocab: list of tokens in order (2000 tokens)            â”‚
â”‚     â””â”€ idf: IDF weights (2000 values)                          â”‚
â”‚                                                                 â”‚
â”‚  2. Extract Model Weights                                      â”‚
â”‚     For each expert MLP (text, struct, diff):                  â”‚
â”‚     â”œâ”€ Layer 1 weight: [128 Ã— input_dim]                       â”‚
â”‚     â”œâ”€ Layer 1 bias: [128]                                     â”‚
â”‚     â”œâ”€ Layer 2 weight: [128 Ã— 128]                             â”‚
â”‚     â””â”€ Layer 2 bias: [128]                                     â”‚
â”‚                                                                 â”‚
â”‚     For classifier:                                             â”‚
â”‚     â”œâ”€ weight: [num_classes Ã— 384]                             â”‚
â”‚     â””â”€ bias: [num_classes]                                     â”‚
â”‚                                                                 â”‚
â”‚  3. Convert to JSON (JavaScript-compatible)                    â”‚
â”‚     model_data.json = {                                        â”‚
â”‚       "tfidf": {                                               â”‚
â”‚         "vocab": ["allow", "accept", ...],                     â”‚
â”‚         "idf": [0.3, 0.5, ...]                                 â”‚
â”‚       },                                                        â”‚
â”‚       "model": {                                               â”‚
â”‚         "txt_mlp": {                                           â”‚
â”‚           "l1_weight": [[...], [...]],                        â”‚
â”‚           "l1_bias": [...],                                    â”‚
â”‚           "l2_weight": [[...], [...]],                        â”‚
â”‚           "l2_bias": [...]                                     â”‚
â”‚         },                                                      â”‚
â”‚         "struct_mlp": {...},                                   â”‚
â”‚         "diff_mlp": {...},                                     â”‚
â”‚         "fc": {                                                â”‚
â”‚           "weight": [[...], [...]],                           â”‚
â”‚           "bias": [...]                                        â”‚
â”‚         }                                                       â”‚
â”‚       },                                                        â”‚
â”‚       "metadata": {                                            â”‚
â”‚         "labels": {0: "POLICY_CREATED", ...},                  â”‚
â”‚         "struct_dim": 847,                                     â”‚
â”‚         "diff_dim": 200,                                       â”‚
â”‚         "feature_keys": ["name", "action", ...]               â”‚
â”‚       }                                                        â”‚
â”‚     }                                                           â”‚
â”‚                                                                 â”‚
â”‚  Output: model_data.json (typically ~10 MB)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  Ready to load into ML Inference engine!                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– HOW ML PRE-DETECTION OCCURS

### **The Core Prediction Process**

```
REAL-TIME PREDICTION FLOW:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

User fills form      â†’  Extract 3 feature types  â†’  Feed to MLP  â†’  Get prediction
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User enters:       â”‚  â”‚ TEXT:                â”‚     â”‚ 3-Expertâ”‚     â”‚ Prediction:â”‚
â”‚ name="Allow HTTP"  â”‚  â”‚ â”œâ”€ TFIDF encode       â”‚â”€â”   â”‚ MLP     â”‚â”€â”€â”€â”€â”‚            â”‚
â”‚ action="accept"    â”‚  â”‚ â””â”€ 2000-dim vector   â”‚ â”‚   â”‚ Model   â”‚    â”‚ label:     â”‚
â”‚                    â”‚  â”‚                       â”‚ â”‚   â”‚         â”‚    â”‚ "CREATE"   â”‚
â”‚ srcintf="port1"    â”‚  â”‚ STRUCT:              â”‚ â”‚   â”‚ 3 paths:â”‚    â”‚            â”‚
â”‚ changes:[name,     â”‚  â”‚ â”œâ”€ Binary presence    â”‚â”€â”¼â”€â†’â”‚ â”œâ”€ TXT  â”‚    â”‚ confidence:â”‚
â”‚   action]          â”‚  â”‚ â””â”€ 847-dim vector    â”‚ â”‚   â”‚ â”œâ”€ STR  â”‚    â”‚ 0.92       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                       â”‚ â”‚   â”‚ â””â”€ DIFF â”‚    â”‚            â”‚
                        â”‚ DIFF:                â”‚ â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ timing:    â”‚
                        â”‚ â”œâ”€ Hash changes       â”‚ â”‚                  â”‚ 23ms       â”‚
                        â”‚ â””â”€ 200-dim vector    â”‚â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Why This Architecture?**

| Feature | Why Used | Benefit |
|---------|----------|---------|
| **TEXT (TF-IDF)** | Captures semantic meaning of field values | Understands what data is being configured |
| **STRUCT (Binary)** | Shows which fields are populated | Identifies data structure completeness |
| **DIFF (Hash)** | Records which fields changed | Distinguishes CREATE (many changes) from MODIFY (few changes) |
| **3-Expert MLPs** | Separate processing paths | Each expert specializes in one feature type |
| **Fusion Layer** | Concatenates expert outputs | Combines insights from all 3 perspectives |

### **Example Prediction Scenarios**

```
SCENARIO 1: NEW POLICY CREATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
State:
  After: {name: "Allow HTTP", action: "accept", ...}
  Changes: [name, action, srcintf, dstintf]  â† many changes

Model Decision:
  Text MLP sees: "allow", "http", "accept" (policy-like words)
  Struct MLP sees: [1, 1, 1, 1, ...] (many fields populated)
  Diff MLP sees: bits 45, 165, 89, 200 (4 fields changed)
  
Prediction: "POLICY_CREATED" (conf: 0.92)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 2: POLICY MODIFICATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
State:
  Before: {name: "Allow HTTP", action: "accept", ...}
  After:  {name: "Allow HTTP", action: "drop", ...}  â† different
  Changes: [action]  â† ONE field changed

Model Decision:
  Text MLP sees: same semantic content (policy structure)
  Struct MLP sees: same fields populated (structure unchanged)
  Diff MLP sees: only 1 bit set (one field changed)
  
Prediction: "POLICY_MODIFIED" (conf: 0.88)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 3: POLICY DELETION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
State:
  After: {name: "Allow HTTP"}  â† minimal data
  Changes: [all fields cleared]  â† many changes to empty

Model Decision:
  Text MLP sees: minimal semantic content
  Struct MLP sees: [0, 0, 0, ...] (few fields populated)
  Diff MLP sees: many bits set (many fields changed)
  
Prediction: "POLICY_DELETED" (conf: 0.85)
```

---

## ğŸ“¦ MODULE DESCRIPTIONS

### **1. universal_field_extractor.js**
**Purpose**: Extract raw form values without HTML structure

**Key Functions**:
- `startMonitoring()`: Detects form elements on page load
- `extractFormValues(form)`: Gets all input values
- `getFieldKey(element)`: Maps form field to canonical name
- `detectVendor(url)`: Identifies which vendor (FortiGate, Palo Alto, etc.)

**Output**: Raw data with field names and values

---

### **2. ml-unified-collector.js**
**Purpose**: Normalize vendor-specific data to canonical format

**Key Functions**:
- `processUniversalEvent(data)`: Receive extracted data
- `createCanonicalSample(rawData)`: Map to standard schema
- `mapFields(data, vendor, objectType)`: Apply vendor_field_map.json
- `detectVendor(url)`: Parse URL to get vendor name
- `detectObjectType(url)`: Parse URL to get object type (policy, interface, etc.)

**Output**: Canonical samples ready for training or inference

---

### **3. ml-inference.js**
**Purpose**: Run ML predictions in JavaScript

**Key Methods**:
- `constructor(modelData)`: Load trained model
- `tfidfTransform(text)`: Convert text to TF-IDF vector
- `flatten(obj)`: Extract struct features
- `getDiffVector(mods)`: Hash changed field names
- `mlpForward(x, weights)`: Pass data through MLP layer
- `predict(sample)`: Main inference function

**Output**: Prediction with confidence score

---

### **4. preprocessing.py**
**Purpose**: Convert raw JSON samples to PyTorch tensors

**Process**:
1. Read data.json (1000 canonical samples)
2. Extract 4 feature types for each sample
3. Fit TfidfVectorizer on text
4. Create binary struct vectors
5. Hash field changes into binary vectors
6. Map labels to indices
7. Save as train.pkl (PyTorch-compatible)

**Output**: train.pkl (1000 Ã— [2000 + 847 + 200] features)

---

### **5. train.py**
**Purpose**: Train the neural network model

**Architecture**:
- 3-Expert MLPs (Text, Struct, Diff)
- Each expert: 2-layer MLP with ReLU
- Fusion: Concatenate + Linear classifier
- Loss: CrossEntropyLoss
- Optimizer: Adam (lr=1e-3)
- Epochs: 25

**Output**: model_artifacts.pkl (trained weights + metadata)

---

### **6. export_model.py**
**Purpose**: Convert PyTorch model to JavaScript-compatible JSON

**Process**:
1. Load model_artifacts.pkl
2. Extract vocabulary & IDF weights
3. Extract all layer weights & biases
4. Convert to JSON arrays
5. Map class indices to labels

**Output**: model_data.json (~10 MB, ready for ml-inference.js)

---

### **7. vendor_field_map.json**
**Purpose**: Schema mapping for vendor-specificâ†’canonical fields

**Structure**:
```json
{
  "fortigate": {
    "policy": {
      "mappings": {
        "ng:$ctrl.policy.name": "name",
        "ng:$ctrl.policy.srcintf": "source_interface",
        ...
      },
      "canonical_fields": ["name", "source_interface", ...],
      "identity_field": "name"
    }
  }
}
```

---

## ğŸ§  MODEL ARCHITECTURE

### **3-Expert Voting Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    3-EXPERT VOTING MODEL                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚                                                                     â”‚
â”‚    INPUT: Sample                                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚    â”‚ data.after: {...}                â”‚                            â”‚
â”‚    â”‚ changes: ["name", "action"]      â”‚                            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                          â”‚                                          â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚          â”‚               â”‚               â”‚                         â”‚
â”‚          â–¼               â–¼               â–¼                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚    â”‚TEXT FEAT â”‚  â”‚STRUCT    â”‚  â”‚DIFF FEAT â”‚                       â”‚
â”‚    â”‚(TFIDF)   â”‚  â”‚FEAT(BIN) â”‚  â”‚(HASH)    â”‚                       â”‚
â”‚    â”‚2000-dim  â”‚  â”‚847-dim   â”‚  â”‚200-dim   â”‚                       â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚         â”‚             â”‚             â”‚                             â”‚
â”‚         â”‚             â”‚             â”‚ EXPERT 1:                  â”‚
â”‚         â”‚             â”‚             â””â”€â†’ Input: 200               â”‚
â”‚         â”‚             â”‚                â”‚ L1: 200â†’128 (ReLU)      â”‚
â”‚         â”‚             â”‚                â”‚ L2: 128â†’128             â”‚
â”‚         â”‚             â”‚                â””â†’ Output: 128-dim        â”‚
â”‚         â”‚             â”‚                                           â”‚
â”‚         â”‚             â”‚ EXPERT 2:                                 â”‚
â”‚         â”‚             â””â”€â†’ Input: 847                             â”‚
â”‚         â”‚                â”‚ L1: 847â†’128 (ReLU)                    â”‚
â”‚         â”‚                â”‚ L2: 128â†’128                           â”‚
â”‚         â”‚                â””â†’ Output: 128-dim                      â”‚
â”‚         â”‚                                                         â”‚
â”‚         â”‚ EXPERT 3:                                               â”‚
â”‚         â””â”€â†’ Input: 2000                                          â”‚
â”‚            â”‚ L1: 2000â†’128 (ReLU)                                 â”‚
â”‚            â”‚ L2: 128â†’128                                         â”‚
â”‚            â””â†’ Output: 128-dim                                    â”‚
â”‚                                                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚  CONCATENATE 3Ã—128  â”‚                       â”‚
â”‚                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                       â”‚
â”‚                    â”‚  384-dim vector     â”‚                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                               â”‚                                   â”‚
â”‚                               â–¼                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚  CLASSIFIER LAYER    â”‚                       â”‚
â”‚                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                       â”‚
â”‚                    â”‚  384 â†’ num_classes   â”‚                       â”‚
â”‚                    â”‚  (Fully Connected)   â”‚                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                               â”‚                                   â”‚
â”‚                               â–¼                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚  SOFTMAX             â”‚                       â”‚
â”‚                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                       â”‚
â”‚                    â”‚  Logits â†’ Probs [0,1]                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                               â”‚                                   â”‚
â”‚                               â–¼                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚  PREDICTION          â”‚                       â”‚
â”‚                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                       â”‚
â”‚                    â”‚  label: "CREATED"    â”‚                       â”‚
â”‚                    â”‚  confidence: 0.92    â”‚                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Why 3 Experts?**

1. **TEXT Expert**: Understands what data is being configured
   - Learns vocabulary patterns (e.g., "allow", "http" â†’ policy)
   - Captures semantic relationships

2. **STRUCT Expert**: Understands data structure completeness
   - Binary presence shows "is this field populated?"
   - Distinguishes complete configs from partial ones

3. **DIFF Expert**: Understands change patterns
   - Records which fields changed
   - CREATE: many changes; MODIFY: few changes

---

## ğŸ”— CODE ARCHITECTURE DIAGRAM

```
CHROME EXTENSION ARCHITECTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MANIFEST.json                             â”‚
â”‚  â”œâ”€ content_scripts: content.js (runs on all pages)           â”‚
â”‚  â”œâ”€ background: background.js (service worker)                â”‚
â”‚  â””â”€ web_accessible_resources:                                 â”‚
â”‚     â”œâ”€ universal_field_extractor.js                           â”‚
â”‚     â”œâ”€ ml-unified-collector.js                                â”‚
â”‚     â”œâ”€ ml-inference.js                                        â”‚
â”‚     â”œâ”€ vendor_field_map.json                                  â”‚
â”‚     â””â”€ model_data.json                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚                 â”‚
         â–¼                 â–¼                 â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  content.js      â”‚  â”‚ background.jsâ”‚  â”‚  popup.html  â”‚
â”‚                  â”‚  â”‚              â”‚  â”‚              â”‚
â”‚  Injects scripts â”‚  â”‚ Storage mgmt â”‚  â”‚  UI/Download â”‚
â”‚  into page       â”‚  â”‚ Analytics    â”‚  â”‚  Controls    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚              â”‚              â”‚
           â–¼              â–¼              â–¼

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ INJECTED       â”‚  â”‚ ML            â”‚  â”‚ ML           â”‚
    â”‚ SCRIPTS        â”‚  â”‚ INFERENCE     â”‚  â”‚ COLLECTOR    â”‚
    â”‚                â”‚  â”‚                â”‚  â”‚              â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚ â”‚ Universal  â”‚ â”‚  â”‚ â”‚ MLInferenceâ”‚ â”‚  â”‚ â”‚ Unified  â”‚ â”‚
    â”‚ â”‚ Field      â”‚ â”‚  â”‚ â”‚ Class      â”‚ â”‚  â”‚ â”‚ Collectorâ”‚ â”‚
    â”‚ â”‚ Extractor  â”‚ â”‚  â”‚ â”‚            â”‚ â”‚  â”‚ â”‚          â”‚ â”‚
    â”‚ â”‚            â”‚ â”‚  â”‚ â”‚ predict()  â”‚ â”‚  â”‚ â”‚ Process  â”‚ â”‚
    â”‚ â”‚ Extracts:  â”‚ â”‚  â”‚ â”‚ methods()  â”‚ â”‚  â”‚ â”‚ Event()  â”‚ â”‚
    â”‚ â”‚ - Before   â”‚ â”‚  â”‚ â”‚            â”‚ â”‚  â”‚ â”‚          â”‚ â”‚
    â”‚ â”‚ - After    â”‚ â”‚  â”‚ â”‚ Uses:      â”‚ â”‚  â”‚ â”‚ Maps to: â”‚ â”‚
    â”‚ â”‚ - Changes  â”‚ â”‚  â”‚ â”‚ - TFIDF    â”‚ â”‚  â”‚ â”‚ - Vendor â”‚ â”‚
    â”‚ â”‚            â”‚ â”‚  â”‚ â”‚ - Struct   â”‚ â”‚  â”‚ â”‚ - Object â”‚ â”‚
    â”‚ â”‚ Broadcasts:â”‚ â”‚  â”‚ â”‚ - Diff     â”‚ â”‚  â”‚ â”‚   Type   â”‚ â”‚
    â”‚ â”‚ UNIVERSAL_ â”‚ â”‚  â”‚ â”‚            â”‚ â”‚  â”‚ â”‚ - Fields â”‚ â”‚
    â”‚ â”‚ EVENT_     â”‚ â”‚  â”‚ â”‚ Loads:     â”‚ â”‚  â”‚ â”‚          â”‚ â”‚
    â”‚ â”‚ SAVED      â”‚ â”‚  â”‚ â”‚ model_data â”‚ â”‚  â”‚ â”‚ Stores:  â”‚ â”‚
    â”‚ â”‚            â”‚ â”‚  â”‚ â”‚ .json      â”‚ â”‚  â”‚ â”‚ - Memory â”‚ â”‚
    â”‚ â”‚            â”‚ â”‚  â”‚ â”‚            â”‚ â”‚  â”‚ â”‚ - IndexDBâ”‚ â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

           â”‚                   â”‚                  â”‚
           â”‚ window.post       â”‚ Prediction      â”‚ Training
           â”‚ Message()         â”‚ Result          â”‚ Data
           â”‚                   â”‚                 â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  USER/POPUP          â”‚
                    â”‚                      â”‚
                    â”‚ Shows prediction     â”‚
                    â”‚ Displays confidence  â”‚
                    â”‚ Export button        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PYTHON DATA PIPELINE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser Export: data.json      â”‚  â† 1000 canonical samples
â”‚  (1000 samples Ã— 5 fields)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  preprocessing.py     â”‚  â† Feature engineering
    â”‚                      â”‚
    â”‚  Extract:            â”‚
    â”‚  â”œâ”€ Text (TFIDF)     â”‚
    â”‚  â”œâ”€ Struct (Binary)   â”‚
    â”‚  â”œâ”€ Diff (Hashed)     â”‚
    â”‚  â””â”€ Labels (Strings)  â”‚
    â”‚                      â”‚
    â”‚  Output: train.pkl   â”‚
    â”‚  1000 Ã— 3047 tensor  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  train.py            â”‚  â† Model training
    â”‚                      â”‚
    â”‚  Load: train.pkl     â”‚
    â”‚  Model:              â”‚
    â”‚  â”œâ”€ 3 Expert MLPs    â”‚
    â”‚  â”œâ”€ Fusion Layer     â”‚
    â”‚  â”œâ”€ Classifier       â”‚
    â”‚                      â”‚
    â”‚  Training:           â”‚
    â”‚  â”œâ”€ 25 epochs        â”‚
    â”‚  â”œâ”€ Batch size: 4    â”‚
    â”‚  â”œâ”€ Adam optimizer    â”‚
    â”‚  â””â”€ CrossEntropy loss â”‚
    â”‚                      â”‚
    â”‚  Output:             â”‚
    â”‚  model_artifacts.pkl â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  export_model.py     â”‚  â† JS export
    â”‚                      â”‚
    â”‚  Load: model_artifacts.pkl
    â”‚  Extract:            â”‚
    â”‚  â”œâ”€ Weights/Biases   â”‚
    â”‚  â”œâ”€ Vocab & IDF      â”‚
    â”‚  â””â”€ Labels           â”‚
    â”‚                      â”‚
    â”‚  Convert to JSON     â”‚
    â”‚                      â”‚
    â”‚  Output:             â”‚
    â”‚  model_data.json     â”‚
    â”‚  (~10 MB)            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Back to Extension   â”‚  â† ml-inference.js loads
    â”‚  model_data.json     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ KEY INSIGHTS

### **Why This Design Works**

1. **Vendor-Agnostic**: Uses vendor_field_map.json to support multiple vendors
2. **Multi-Modal Features**: 3 independent feature extractors improve robustness
3. **Real-Time Inference**: JavaScript execution in browser = instant predictions
4. **Flexible Training**: Python backend enables model updates without code changes
5. **Transparent**: Can inspect predicted confidence and feature values

### **Data Flow Summary**

```
Extension          Extract Data           Normalize          Predict
Runtime      â†’     (Raw Values)     â†’     (Canonical)   â†’    (ML Model)
             
  user fills         Values only            Field mapping       3-Expert
  form         extracted from DOM          using vendor_map     MLP predicts
                                           creates training     operation
                                           samples              type
```

### **Model's Decision Process**

```
When predicting an operation, the model considers:

1. What data was entered? (TEXT MLP)
   â†’ "allow", "http" words indicate a policy

2. Which fields were populated? (STRUCT MLP)
   â†’ Full structure indicates complete config

3. Which fields changed? (DIFF MLP)
   â†’ Many changes = CREATE, Few changes = MODIFY

FUSION: Combine all 3 perspectives
RESULT: High-confidence prediction of operation
```

This architecture enables intelligent pre-detection of configuration operations before user submission!
